{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, sys\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('46a_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tripid</th>\n",
       "      <th>dt</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>rush_hour</th>\n",
       "      <th>progrnum</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>cum_duration</th>\n",
       "      <th>temp</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>weather_main</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5957152</td>\n",
       "      <td>1514988500</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>808.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>8.01</td>\n",
       "      <td>996</td>\n",
       "      <td>76</td>\n",
       "      <td>12.86</td>\n",
       "      <td>Rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5957152</td>\n",
       "      <td>1514988542</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>809.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>8.01</td>\n",
       "      <td>996</td>\n",
       "      <td>76</td>\n",
       "      <td>12.86</td>\n",
       "      <td>Rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5957152</td>\n",
       "      <td>1514988594</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>810.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>8.01</td>\n",
       "      <td>996</td>\n",
       "      <td>76</td>\n",
       "      <td>12.86</td>\n",
       "      <td>Rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5957152</td>\n",
       "      <td>1514988693</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>811.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>8.01</td>\n",
       "      <td>996</td>\n",
       "      <td>76</td>\n",
       "      <td>12.86</td>\n",
       "      <td>Rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5957152</td>\n",
       "      <td>1514988709</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>812.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>8.01</td>\n",
       "      <td>996</td>\n",
       "      <td>76</td>\n",
       "      <td>12.86</td>\n",
       "      <td>Rain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   tripid          dt  dayofweek  month  day  hour  rush_hour  \\\n",
       "0           0  5957152  1514988500          2      1    3    14          0   \n",
       "1           1  5957152  1514988542          2      1    3    14          0   \n",
       "2           2  5957152  1514988594          2      1    3    14          0   \n",
       "3           3  5957152  1514988693          2      1    3    14          0   \n",
       "4           4  5957152  1514988709          2      1    3    14          0   \n",
       "\n",
       "   progrnum  stop_id  cum_duration  temp  pressure  humidity  wind_speed  \\\n",
       "0         1    808.0          42.0  8.01       996        76       12.86   \n",
       "1         2    809.0          94.0  8.01       996        76       12.86   \n",
       "2         3    810.0         193.0  8.01       996        76       12.86   \n",
       "3         4    811.0         209.0  8.01       996        76       12.86   \n",
       "4         5    812.0         252.0  8.01       996        76       12.86   \n",
       "\n",
       "  weather_main  \n",
       "0         Rain  \n",
       "1         Rain  \n",
       "2         Rain  \n",
       "3         Rain  \n",
       "4         Rain  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1945346, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clouds     1543819\n",
       "Rain        223989\n",
       "Drizzle      98572\n",
       "Clear        46312\n",
       "Snow         12798\n",
       "Fog          10385\n",
       "Mist          9107\n",
       "Smoke          364\n",
       "Name: weather_main, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['weather_main'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['dayofweek', 'month', 'day','hour', 'rush_hour', 'progrnum','stop_id','temp', 'pressure', 'humidity', 'wind_speed', 'weather_main']\n",
    "target = 'cum_duration'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather = pd.get_dummies(df_test.weather_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clear</th>\n",
       "      <th>Clouds</th>\n",
       "      <th>Drizzle</th>\n",
       "      <th>Fog</th>\n",
       "      <th>Mist</th>\n",
       "      <th>Rain</th>\n",
       "      <th>Smoke</th>\n",
       "      <th>Snow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clear  Clouds  Drizzle  Fog  Mist  Rain  Smoke  Snow\n",
       "0      0       0        0    0     0     1      0     0\n",
       "1      0       0        0    0     0     1      0     0\n",
       "2      0       0        0    0     0     1      0     0\n",
       "3      0       0        0    0     0     1      0     0\n",
       "4      0       0        0    0     0     1      0     0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=df_test.drop([\"weather_main\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.concat([df_test,df_weather],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>rush_hour</th>\n",
       "      <th>progrnum</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>temp</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>Clear</th>\n",
       "      <th>Clouds</th>\n",
       "      <th>Drizzle</th>\n",
       "      <th>Fog</th>\n",
       "      <th>Mist</th>\n",
       "      <th>Rain</th>\n",
       "      <th>Smoke</th>\n",
       "      <th>Snow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>808.0</td>\n",
       "      <td>8.01</td>\n",
       "      <td>996</td>\n",
       "      <td>76</td>\n",
       "      <td>12.86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>809.0</td>\n",
       "      <td>8.01</td>\n",
       "      <td>996</td>\n",
       "      <td>76</td>\n",
       "      <td>12.86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>810.0</td>\n",
       "      <td>8.01</td>\n",
       "      <td>996</td>\n",
       "      <td>76</td>\n",
       "      <td>12.86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>811.0</td>\n",
       "      <td>8.01</td>\n",
       "      <td>996</td>\n",
       "      <td>76</td>\n",
       "      <td>12.86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>812.0</td>\n",
       "      <td>8.01</td>\n",
       "      <td>996</td>\n",
       "      <td>76</td>\n",
       "      <td>12.86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dayofweek  month  day  hour  rush_hour  progrnum  stop_id  temp  pressure  \\\n",
       "0          2      1    3    14          0         1    808.0  8.01       996   \n",
       "1          2      1    3    14          0         2    809.0  8.01       996   \n",
       "2          2      1    3    14          0         3    810.0  8.01       996   \n",
       "3          2      1    3    14          0         4    811.0  8.01       996   \n",
       "4          2      1    3    14          0         5    812.0  8.01       996   \n",
       "\n",
       "   humidity  wind_speed  Clear  Clouds  Drizzle  Fog  Mist  Rain  Smoke  Snow  \n",
       "0        76       12.86      0       0        0    0     0     1      0     0  \n",
       "1        76       12.86      0       0        0    0     0     1      0     0  \n",
       "2        76       12.86      0       0        0    0     0     1      0     0  \n",
       "3        76       12.86      0       0        0    0     0     1      0     0  \n",
       "4        76       12.86      0       0        0    0     0     1      0     0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_test\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)#maybe turn shuffle off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The common choices for activation functions are logistic sigmoid and hyperbolic tangens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 245700.28445166\n",
      "Iteration 2, loss = 128654.84703657\n",
      "Iteration 3, loss = 119739.94863055\n",
      "Iteration 4, loss = 111742.52067999\n",
      "Iteration 5, loss = 102600.47550473\n",
      "Iteration 6, loss = 95806.16822820\n",
      "Iteration 7, loss = 91594.97363560\n",
      "Iteration 8, loss = 89072.93260405\n",
      "Iteration 9, loss = 87649.52518539\n",
      "Iteration 10, loss = 86758.65943649\n",
      "Iteration 11, loss = 86009.26047394\n",
      "Iteration 12, loss = 85620.80294664\n",
      "Iteration 13, loss = 85274.88017774\n",
      "Iteration 14, loss = 84872.49161325\n",
      "Iteration 15, loss = 84682.51200108\n",
      "Iteration 16, loss = 84476.29622642\n",
      "Iteration 17, loss = 84228.38094704\n",
      "Iteration 18, loss = 83939.22647398\n",
      "Iteration 19, loss = 83708.02248931\n",
      "Iteration 20, loss = 83468.41088894\n",
      "Iteration 21, loss = 83433.39096684\n",
      "Iteration 22, loss = 83165.25829613\n",
      "Iteration 23, loss = 83051.12450930\n",
      "Iteration 24, loss = 82855.12081351\n",
      "Iteration 25, loss = 82438.92871113\n",
      "Iteration 26, loss = 81745.36732577\n",
      "Iteration 27, loss = 81472.12855519\n",
      "Iteration 28, loss = 81190.08993531\n",
      "Iteration 29, loss = 80960.50614625\n",
      "Iteration 30, loss = 80776.76940759\n",
      "Iteration 31, loss = 80624.37288140\n",
      "Iteration 32, loss = 80373.76091818\n",
      "Iteration 33, loss = 80024.89627581\n",
      "Iteration 34, loss = 79781.39269196\n",
      "Iteration 35, loss = 79343.61376628\n",
      "Iteration 36, loss = 78996.43162633\n",
      "Iteration 37, loss = 78522.68698126\n",
      "Iteration 38, loss = 78001.82996186\n",
      "Iteration 39, loss = 77350.63494975\n",
      "Iteration 40, loss = 76723.29220932\n",
      "Iteration 41, loss = 76122.48723228\n",
      "Iteration 42, loss = 75772.18345302\n",
      "Iteration 43, loss = 75403.74189066\n",
      "Iteration 44, loss = 75238.42074395\n",
      "Iteration 45, loss = 74921.70626087\n",
      "Iteration 46, loss = 74709.14450374\n",
      "Iteration 47, loss = 74575.72302748\n",
      "Iteration 48, loss = 74364.41387191\n",
      "Iteration 49, loss = 74118.52892218\n",
      "Iteration 50, loss = 73950.83302845\n",
      "Iteration 51, loss = 73826.92878547\n",
      "Iteration 52, loss = 73561.98622538\n",
      "Iteration 53, loss = 73369.52477426\n",
      "Iteration 54, loss = 73262.85541286\n",
      "Iteration 55, loss = 73102.43158161\n",
      "Iteration 56, loss = 72874.45994948\n",
      "Iteration 57, loss = 72660.85221615\n",
      "Iteration 58, loss = 72529.87103878\n",
      "Iteration 59, loss = 72353.65245368\n",
      "Iteration 60, loss = 72171.12511778\n",
      "Iteration 61, loss = 72067.85692998\n",
      "Iteration 62, loss = 71828.95878385\n",
      "Iteration 63, loss = 71588.26530310\n",
      "Iteration 64, loss = 71448.59668965\n",
      "Iteration 65, loss = 71413.06824002\n",
      "Iteration 66, loss = 71249.75988448\n",
      "Iteration 67, loss = 71088.10699040\n",
      "Iteration 68, loss = 70891.26441719\n",
      "Iteration 69, loss = 70806.58851166\n",
      "Iteration 70, loss = 70720.85676793\n",
      "Iteration 71, loss = 70552.01618543\n",
      "Iteration 72, loss = 70480.72565596\n",
      "Iteration 73, loss = 70374.64728300\n",
      "Iteration 74, loss = 70362.08393166\n",
      "Iteration 75, loss = 70167.35019198\n",
      "Iteration 76, loss = 70081.81818522\n",
      "Iteration 77, loss = 69979.32901564\n",
      "Iteration 78, loss = 69880.48330121\n",
      "Iteration 79, loss = 69648.99416643\n",
      "Iteration 80, loss = 69575.38649700\n",
      "Iteration 81, loss = 69384.29682808\n",
      "Iteration 82, loss = 69268.39164863\n",
      "Iteration 83, loss = 69034.66173860\n",
      "Iteration 84, loss = 68829.34808650\n",
      "Iteration 85, loss = 68764.10401266\n",
      "Iteration 86, loss = 68536.73336677\n",
      "Iteration 87, loss = 68405.33088209\n",
      "Iteration 88, loss = 68397.28232332\n",
      "Iteration 89, loss = 68114.76563572\n",
      "Iteration 90, loss = 68117.40932187\n",
      "Iteration 91, loss = 68094.63526543\n",
      "Iteration 92, loss = 67930.74720624\n",
      "Iteration 93, loss = 67687.94575000\n",
      "Iteration 94, loss = 67714.08227069\n",
      "Iteration 95, loss = 67681.11685264\n",
      "Iteration 96, loss = 67635.42939223\n",
      "Iteration 97, loss = 67662.94944821\n",
      "Iteration 98, loss = 67492.40992153\n",
      "Iteration 99, loss = 67417.88430402\n",
      "Iteration 100, loss = 67380.11412558\n",
      "Iteration 101, loss = 67276.94097088\n",
      "Iteration 102, loss = 67282.43710545\n",
      "Iteration 103, loss = 67232.03541968\n",
      "Iteration 104, loss = 67127.53227640\n",
      "Iteration 105, loss = 67124.75942116\n",
      "Iteration 106, loss = 67061.95322484\n",
      "Iteration 107, loss = 66963.27807324\n",
      "Iteration 108, loss = 66894.94127694\n",
      "Iteration 109, loss = 66953.05897209\n",
      "Iteration 110, loss = 66875.88257675\n",
      "Iteration 111, loss = 66800.77787671\n",
      "Iteration 112, loss = 66828.50383469\n",
      "Iteration 113, loss = 66729.49320140\n",
      "Iteration 114, loss = 66702.02149004\n",
      "Iteration 115, loss = 66596.80181708\n",
      "Iteration 116, loss = 66649.90795347\n",
      "Iteration 117, loss = 66564.40755425\n",
      "Iteration 118, loss = 66549.26385477\n",
      "Iteration 119, loss = 66432.41659010\n",
      "Iteration 120, loss = 66432.87627309\n",
      "Iteration 121, loss = 66440.18456459\n",
      "Iteration 122, loss = 66425.44068449\n",
      "Iteration 123, loss = 66402.54095670\n",
      "Iteration 124, loss = 66368.46354548\n",
      "Iteration 125, loss = 66333.22270789\n",
      "Iteration 126, loss = 66385.75544988\n",
      "Iteration 127, loss = 66319.11363373\n",
      "Iteration 128, loss = 66215.90979691\n",
      "Iteration 129, loss = 66239.59524380\n",
      "Iteration 130, loss = 66213.90854640\n",
      "Iteration 131, loss = 66292.89754235\n",
      "Iteration 132, loss = 66191.35084944\n",
      "Iteration 133, loss = 66126.71431308\n",
      "Iteration 134, loss = 66059.82102652\n",
      "Iteration 135, loss = 66103.08176763\n",
      "Iteration 136, loss = 66021.35065450\n",
      "Iteration 137, loss = 66022.38002067\n",
      "Iteration 138, loss = 66006.08816809\n",
      "Iteration 139, loss = 65998.47187102\n",
      "Iteration 140, loss = 66002.37186738\n",
      "Iteration 141, loss = 65973.82761598\n",
      "Iteration 142, loss = 65910.43013232\n",
      "Iteration 143, loss = 65963.44503058\n",
      "Iteration 144, loss = 65909.84725674\n",
      "Iteration 145, loss = 65844.96521556\n",
      "Iteration 146, loss = 65859.84912007\n",
      "Iteration 147, loss = 65861.35057680\n",
      "Iteration 148, loss = 65825.62074234\n",
      "Iteration 149, loss = 65856.80474997\n",
      "Iteration 150, loss = 65775.91200964\n",
      "Iteration 151, loss = 65777.86630367\n",
      "Iteration 152, loss = 65709.36926524\n",
      "Iteration 153, loss = 65769.02522363\n",
      "Iteration 154, loss = 65692.84147665\n",
      "Iteration 155, loss = 65804.30209120\n",
      "Iteration 156, loss = 65705.08100909\n",
      "Iteration 157, loss = 65618.02018852\n",
      "Iteration 158, loss = 65680.04996779\n",
      "Iteration 159, loss = 65629.77910024\n",
      "Iteration 160, loss = 65571.27062738\n",
      "Iteration 161, loss = 65620.43053141\n",
      "Iteration 162, loss = 65563.71021467\n",
      "Iteration 163, loss = 65562.32597471\n",
      "Iteration 164, loss = 65577.65846862\n",
      "Iteration 165, loss = 65470.59066864\n",
      "Iteration 166, loss = 65542.48224443\n",
      "Iteration 167, loss = 65528.25357977\n",
      "Iteration 168, loss = 65411.73465181\n",
      "Iteration 169, loss = 65542.68022649\n",
      "Iteration 170, loss = 65384.10076389\n",
      "Iteration 171, loss = 65413.45378532\n",
      "Iteration 172, loss = 65432.21523736\n",
      "Iteration 173, loss = 65331.39111717\n",
      "Iteration 174, loss = 65272.00702437\n",
      "Iteration 175, loss = 65323.99833196\n",
      "Iteration 176, loss = 65331.92285983\n",
      "Iteration 177, loss = 65346.69324740\n",
      "Iteration 178, loss = 65249.23246097\n",
      "Iteration 179, loss = 65287.30045912\n",
      "Iteration 180, loss = 65215.81980545\n",
      "Iteration 181, loss = 65208.79820167\n",
      "Iteration 182, loss = 65308.33441453\n",
      "Iteration 183, loss = 65200.29499854\n",
      "Iteration 184, loss = 65177.62456817\n",
      "Iteration 185, loss = 65136.46388431\n",
      "Iteration 186, loss = 65156.45935400\n",
      "Iteration 187, loss = 65212.23449714\n",
      "Iteration 188, loss = 65240.14983688\n",
      "Iteration 189, loss = 65023.66771342\n",
      "Iteration 190, loss = 65137.65872843\n",
      "Iteration 191, loss = 65129.61931155\n",
      "Iteration 192, loss = 65127.31520944\n",
      "Iteration 193, loss = 65076.30806657\n",
      "Iteration 194, loss = 65083.54821910\n",
      "Iteration 195, loss = 65046.17001805\n",
      "Iteration 196, loss = 65071.44530511\n",
      "Iteration 197, loss = 65037.63865583\n",
      "Iteration 198, loss = 65055.58743819\n",
      "Iteration 199, loss = 65011.33282682\n",
      "Iteration 200, loss = 65014.07976821\n",
      "Iteration 201, loss = 64982.05743187\n",
      "Iteration 202, loss = 64989.82114910\n",
      "Iteration 203, loss = 64943.52548034\n",
      "Iteration 204, loss = 65055.34062188\n",
      "Iteration 205, loss = 64862.16587620\n",
      "Iteration 206, loss = 64913.13437891\n",
      "Iteration 207, loss = 64893.76058536\n",
      "Iteration 208, loss = 64819.77311983\n",
      "Iteration 209, loss = 64824.57253479\n",
      "Iteration 210, loss = 64813.50858869\n",
      "Iteration 211, loss = 64862.69060832\n",
      "Iteration 212, loss = 64824.90505002\n",
      "Iteration 213, loss = 64817.90005012\n",
      "Iteration 214, loss = 64837.98476518\n",
      "Iteration 215, loss = 64728.53909120\n",
      "Iteration 216, loss = 64851.85045019\n",
      "Iteration 217, loss = 64775.31859246\n",
      "Iteration 218, loss = 64721.16185999\n",
      "Iteration 219, loss = 64775.03763636\n",
      "Iteration 220, loss = 64729.10061707\n",
      "Iteration 221, loss = 64824.22734433\n",
      "Iteration 222, loss = 64720.15459597\n",
      "Iteration 223, loss = 64699.46615142\n",
      "Iteration 224, loss = 64682.27763207\n",
      "Iteration 225, loss = 64631.23609769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 226, loss = 64651.19864138\n",
      "Iteration 227, loss = 64675.93232109\n",
      "Iteration 228, loss = 64648.57794645\n",
      "Iteration 229, loss = 64610.62410491\n",
      "Iteration 230, loss = 64570.39984904\n",
      "Iteration 231, loss = 64609.23765199\n",
      "Iteration 232, loss = 64641.92570268\n",
      "Iteration 233, loss = 64606.66872887\n",
      "Iteration 234, loss = 64582.76951905\n",
      "Iteration 235, loss = 64597.09256558\n",
      "Iteration 236, loss = 64633.02650039\n",
      "Iteration 237, loss = 64583.13003059\n",
      "Iteration 238, loss = 64618.03132306\n",
      "Iteration 239, loss = 64518.75403174\n",
      "Iteration 240, loss = 64558.30934950\n",
      "Iteration 241, loss = 64532.63490949\n",
      "Iteration 242, loss = 64494.50741178\n",
      "Iteration 243, loss = 64532.92662133\n",
      "Iteration 244, loss = 64468.24504038\n",
      "Iteration 245, loss = 64551.50746650\n",
      "Iteration 246, loss = 64487.50197256\n",
      "Iteration 247, loss = 64434.21017624\n",
      "Iteration 248, loss = 64421.84332312\n",
      "Iteration 249, loss = 64480.90694253\n",
      "Iteration 250, loss = 64340.06236962\n",
      "Iteration 251, loss = 64510.06021412\n",
      "Iteration 252, loss = 64493.47284577\n",
      "Iteration 253, loss = 64369.60569373\n",
      "Iteration 254, loss = 64422.00405361\n",
      "Iteration 255, loss = 64332.66993949\n",
      "Iteration 256, loss = 64436.78631144\n",
      "Iteration 257, loss = 64329.57403904\n",
      "Iteration 258, loss = 64405.36076067\n",
      "Iteration 259, loss = 64313.43492538\n",
      "Iteration 260, loss = 64361.87327208\n",
      "Iteration 261, loss = 64355.64113939\n",
      "Iteration 262, loss = 64263.13121970\n",
      "Iteration 263, loss = 64387.53348857\n",
      "Iteration 264, loss = 64278.58207612\n",
      "Iteration 265, loss = 64253.62850864\n",
      "Iteration 266, loss = 64336.92261687\n",
      "Iteration 267, loss = 64259.88877651\n",
      "Iteration 268, loss = 64305.77338827\n",
      "Iteration 269, loss = 64227.83338975\n",
      "Iteration 270, loss = 64274.71266954\n",
      "Iteration 271, loss = 64249.15188203\n",
      "Iteration 272, loss = 64191.96823101\n",
      "Iteration 273, loss = 64176.66603582\n",
      "Iteration 274, loss = 64193.96243633\n",
      "Iteration 275, loss = 64178.12034950\n",
      "Iteration 276, loss = 64169.02123149\n",
      "Iteration 277, loss = 64082.71535344\n",
      "Iteration 278, loss = 64109.31557948\n",
      "Iteration 279, loss = 64155.59915735\n",
      "Iteration 280, loss = 64148.18861527\n",
      "Iteration 281, loss = 64080.92652193\n",
      "Iteration 282, loss = 64107.29233342\n",
      "Iteration 283, loss = 64102.89120789\n",
      "Iteration 284, loss = 64055.56838740\n",
      "Iteration 285, loss = 64047.08364171\n",
      "Iteration 286, loss = 64099.24485635\n",
      "Iteration 287, loss = 64051.34778645\n",
      "Iteration 288, loss = 64060.50824023\n",
      "Iteration 289, loss = 64017.01948150\n",
      "Iteration 290, loss = 64029.95258093\n",
      "Iteration 291, loss = 63984.10672428\n",
      "Iteration 292, loss = 64030.45522365\n",
      "Iteration 293, loss = 64019.33299747\n",
      "Iteration 294, loss = 63968.44255505\n",
      "Iteration 295, loss = 64031.06424629\n",
      "Iteration 296, loss = 63968.46774033\n",
      "Iteration 297, loss = 63956.14057212\n",
      "Iteration 298, loss = 63918.22071777\n",
      "Iteration 299, loss = 63974.77934852\n",
      "Iteration 300, loss = 63977.10804597\n",
      "Iteration 301, loss = 63962.36457273\n",
      "Iteration 302, loss = 63933.27373678\n",
      "Iteration 303, loss = 63915.70420490\n",
      "Iteration 304, loss = 63859.54185235\n",
      "Iteration 305, loss = 63909.48528739\n",
      "Iteration 306, loss = 63873.66932242\n",
      "Iteration 307, loss = 63984.83863138\n",
      "Iteration 308, loss = 63851.79788817\n",
      "Iteration 309, loss = 63908.03521826\n",
      "Iteration 310, loss = 63894.49125455\n",
      "Iteration 311, loss = 63805.53480472\n",
      "Iteration 312, loss = 63884.44084214\n",
      "Iteration 313, loss = 63767.54692615\n",
      "Iteration 314, loss = 63793.63126344\n",
      "Iteration 315, loss = 63865.10010877\n",
      "Iteration 316, loss = 63933.20967713\n",
      "Iteration 317, loss = 63868.75977638\n",
      "Iteration 318, loss = 63765.95555974\n",
      "Iteration 319, loss = 63764.03054275\n",
      "Iteration 320, loss = 63788.51178838\n",
      "Iteration 321, loss = 63739.73234327\n",
      "Iteration 322, loss = 63788.54174623\n",
      "Iteration 323, loss = 63730.68610453\n",
      "Iteration 324, loss = 63692.68974823\n",
      "Iteration 325, loss = 63799.96371452\n",
      "Iteration 326, loss = 63788.41994982\n",
      "Iteration 327, loss = 63692.11391410\n",
      "Iteration 328, loss = 63730.14499596\n",
      "Iteration 329, loss = 63738.59447533\n",
      "Iteration 330, loss = 63729.92186455\n",
      "Iteration 331, loss = 63790.48970668\n",
      "Iteration 332, loss = 63760.46163444\n",
      "Iteration 333, loss = 63705.45156963\n",
      "Iteration 334, loss = 63753.06927387\n",
      "Iteration 335, loss = 63715.45542836\n",
      "Iteration 336, loss = 63688.50737207\n",
      "Iteration 337, loss = 63732.58630112\n",
      "Iteration 338, loss = 63708.98520197\n",
      "Iteration 339, loss = 63694.65605971\n",
      "Iteration 340, loss = 63684.53702199\n",
      "Iteration 341, loss = 63643.84771297\n",
      "Iteration 342, loss = 63680.64029157\n",
      "Iteration 343, loss = 63630.72917717\n",
      "Iteration 344, loss = 63651.18663616\n",
      "Iteration 345, loss = 63604.76870126\n",
      "Iteration 346, loss = 63680.72015966\n",
      "Iteration 347, loss = 63624.79011359\n",
      "Iteration 348, loss = 63629.52741946\n",
      "Iteration 349, loss = 63636.41394116\n",
      "Iteration 350, loss = 63770.23845887\n",
      "Iteration 351, loss = 63613.45325485\n",
      "Iteration 352, loss = 63610.69458904\n",
      "Iteration 353, loss = 63646.17950680\n",
      "Iteration 354, loss = 63606.08267959\n",
      "Iteration 355, loss = 63555.23070228\n",
      "Iteration 356, loss = 63513.23488139\n",
      "Iteration 357, loss = 63603.60109463\n",
      "Iteration 358, loss = 63643.70002469\n",
      "Iteration 359, loss = 63551.29487904\n",
      "Iteration 360, loss = 63623.00894407\n",
      "Iteration 361, loss = 63541.37247410\n",
      "Iteration 362, loss = 63502.14817495\n",
      "Iteration 363, loss = 63554.60954688\n",
      "Iteration 364, loss = 63573.43061954\n",
      "Iteration 365, loss = 63560.48643655\n",
      "Iteration 366, loss = 63536.84861622\n",
      "Iteration 367, loss = 63539.45646170\n",
      "Iteration 368, loss = 63466.24710453\n",
      "Iteration 369, loss = 63532.08208760\n",
      "Iteration 370, loss = 63524.05819659\n",
      "Iteration 371, loss = 63525.06357719\n",
      "Iteration 372, loss = 63597.09028570\n",
      "Iteration 373, loss = 63472.91346412\n",
      "Iteration 374, loss = 63468.98299154\n",
      "Iteration 375, loss = 63479.30984035\n",
      "Iteration 376, loss = 63510.28759030\n",
      "Iteration 377, loss = 63492.67868685\n",
      "Iteration 378, loss = 63459.04516077\n",
      "Iteration 379, loss = 63428.67239143\n",
      "Iteration 380, loss = 63487.91754030\n",
      "Iteration 381, loss = 63400.90480085\n",
      "Iteration 382, loss = 63473.19147374\n",
      "Iteration 383, loss = 63483.93267846\n",
      "Iteration 384, loss = 63459.55716739\n",
      "Iteration 385, loss = 63343.59892114\n",
      "Iteration 386, loss = 63386.41537320\n",
      "Iteration 387, loss = 63350.16342147\n",
      "Iteration 388, loss = 63415.65170589\n",
      "Iteration 389, loss = 63395.99681753\n",
      "Iteration 390, loss = 63446.75195414\n",
      "Iteration 391, loss = 63347.18541021\n",
      "Iteration 392, loss = 63366.55337652\n",
      "Iteration 393, loss = 63455.75830250\n",
      "Iteration 394, loss = 63311.83968928\n",
      "Iteration 395, loss = 63330.24317073\n",
      "Iteration 396, loss = 63363.52288372\n",
      "Iteration 397, loss = 63356.55975242\n",
      "Iteration 398, loss = 63320.23042754\n",
      "Iteration 399, loss = 63364.40650341\n",
      "Iteration 400, loss = 63346.74141496\n",
      "Iteration 401, loss = 63284.98580968\n",
      "Iteration 402, loss = 63302.15535011\n",
      "Iteration 403, loss = 63376.46876815\n",
      "Iteration 404, loss = 63349.11796422\n",
      "Iteration 405, loss = 63316.37728270\n",
      "Iteration 406, loss = 63302.05775777\n",
      "Iteration 407, loss = 63321.53985069\n",
      "Iteration 408, loss = 63385.00302499\n",
      "Iteration 409, loss = 63281.42457920\n",
      "Iteration 410, loss = 63293.44893014\n",
      "Iteration 411, loss = 63235.17048823\n",
      "Iteration 412, loss = 63298.57927347\n",
      "Iteration 413, loss = 63278.48675979\n",
      "Iteration 414, loss = 63311.88835567\n",
      "Iteration 415, loss = 63293.32445561\n",
      "Iteration 416, loss = 63322.50945782\n",
      "Iteration 417, loss = 63261.01660836\n",
      "Iteration 418, loss = 63274.96092156\n",
      "Iteration 419, loss = 63289.19334047\n",
      "Iteration 420, loss = 63350.75572698\n",
      "Iteration 421, loss = 63189.55449270\n",
      "Iteration 422, loss = 63188.82870051\n",
      "Iteration 423, loss = 63213.45039462\n",
      "Iteration 424, loss = 63239.57708368\n",
      "Iteration 425, loss = 63226.43599150\n",
      "Iteration 426, loss = 63219.46866065\n",
      "Iteration 427, loss = 63201.81835131\n",
      "Iteration 428, loss = 63148.89867549\n",
      "Iteration 429, loss = 63169.65025520\n",
      "Iteration 430, loss = 63191.71061990\n",
      "Iteration 431, loss = 63126.05905338\n",
      "Iteration 432, loss = 63161.80294753\n",
      "Iteration 433, loss = 63135.69971780\n",
      "Iteration 434, loss = 63133.75067504\n",
      "Iteration 435, loss = 63137.43861346\n",
      "Iteration 436, loss = 63163.40674191\n",
      "Iteration 437, loss = 63185.78043395\n",
      "Iteration 438, loss = 63089.43615619\n",
      "Iteration 439, loss = 63123.92093637\n",
      "Iteration 440, loss = 63139.60726822\n",
      "Iteration 441, loss = 63146.31803535\n",
      "Iteration 442, loss = 63101.63386132\n",
      "Iteration 443, loss = 63094.34313363\n",
      "Iteration 444, loss = 63159.15818032\n",
      "Iteration 445, loss = 63089.16073563\n",
      "Iteration 446, loss = 63088.99528104\n",
      "Iteration 447, loss = 63093.59144533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 448, loss = 63014.88962866\n",
      "Iteration 449, loss = 63049.80002269\n",
      "Iteration 450, loss = 63080.30450178\n",
      "Iteration 451, loss = 62961.62815951\n",
      "Iteration 452, loss = 63078.81942600\n",
      "Iteration 453, loss = 63021.34719320\n",
      "Iteration 454, loss = 63065.70359584\n",
      "Iteration 455, loss = 63009.52142466\n",
      "Iteration 456, loss = 63030.47305037\n",
      "Iteration 457, loss = 63050.61356376\n",
      "Iteration 458, loss = 63059.83359596\n",
      "Iteration 459, loss = 63013.96096495\n",
      "Iteration 460, loss = 63012.50174660\n",
      "Iteration 461, loss = 62977.76587388\n",
      "Iteration 462, loss = 63013.69535433\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "regr_relu=MLPRegressor(activation=\"relu\",random_state=1, max_iter=500, verbose=1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.928921697898482"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr_relu.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 3284666.25922179\n",
      "Iteration 2, loss = 2188190.56556607\n",
      "Iteration 3, loss = 1408790.11181045\n",
      "Iteration 4, loss = 966204.19625891\n",
      "Iteration 5, loss = 762520.55373673\n",
      "Iteration 6, loss = 672775.88081535\n",
      "Iteration 7, loss = 587857.45731377\n",
      "Iteration 8, loss = 526768.56058935\n",
      "Iteration 9, loss = 464451.96154808\n",
      "Iteration 10, loss = 408374.12141551\n",
      "Iteration 11, loss = 360390.29792473\n",
      "Iteration 12, loss = 319257.81411131\n",
      "Iteration 13, loss = 291741.94281493\n",
      "Iteration 14, loss = 278921.21155221\n",
      "Iteration 15, loss = 254257.91182731\n",
      "Iteration 16, loss = 231099.27654598\n",
      "Iteration 17, loss = 209168.24345341\n",
      "Iteration 18, loss = 189071.38842561\n",
      "Iteration 19, loss = 176741.25779359\n",
      "Iteration 20, loss = 167391.36604846\n",
      "Iteration 21, loss = 156799.58095051\n",
      "Iteration 22, loss = 149596.57201746\n",
      "Iteration 23, loss = 144830.99853375\n",
      "Iteration 24, loss = 140966.97055863\n",
      "Iteration 25, loss = 139357.71122510\n",
      "Iteration 26, loss = 137492.34583624\n",
      "Iteration 27, loss = 135902.25765055\n",
      "Iteration 28, loss = 134350.47127801\n",
      "Iteration 29, loss = 132996.07524462\n",
      "Iteration 30, loss = 129659.90224229\n",
      "Iteration 31, loss = 127312.62443765\n",
      "Iteration 32, loss = 125391.63699982\n",
      "Iteration 33, loss = 123663.47787813\n",
      "Iteration 34, loss = 120743.92072790\n",
      "Iteration 35, loss = 119201.83318411\n",
      "Iteration 36, loss = 117858.72308939\n",
      "Iteration 37, loss = 117039.86455900\n",
      "Iteration 38, loss = 115546.26831967\n",
      "Iteration 39, loss = 114459.86112806\n",
      "Iteration 40, loss = 113954.54687764\n",
      "Iteration 41, loss = 112836.85215028\n",
      "Iteration 42, loss = 111622.27466938\n",
      "Iteration 43, loss = 110948.61103285\n",
      "Iteration 44, loss = 109349.71815833\n",
      "Iteration 45, loss = 108452.16527802\n",
      "Iteration 46, loss = 109215.80489970\n",
      "Iteration 47, loss = 107699.84491189\n",
      "Iteration 48, loss = 107206.22037039\n",
      "Iteration 49, loss = 106800.46121092\n",
      "Iteration 50, loss = 105995.05119084\n",
      "Iteration 51, loss = 104684.71068834\n",
      "Iteration 52, loss = 104059.62187920\n",
      "Iteration 53, loss = 103819.07047744\n",
      "Iteration 54, loss = 103234.30476886\n",
      "Iteration 55, loss = 102828.04255559\n",
      "Iteration 56, loss = 102602.92324858\n",
      "Iteration 57, loss = 102222.44616469\n",
      "Iteration 58, loss = 102236.51267882\n",
      "Iteration 59, loss = 101450.13370239\n",
      "Iteration 60, loss = 101584.16893420\n",
      "Iteration 61, loss = 101260.63904188\n",
      "Iteration 62, loss = 101073.83474004\n",
      "Iteration 63, loss = 100950.03715448\n",
      "Iteration 64, loss = 100788.17853456\n",
      "Iteration 65, loss = 100531.40010139\n",
      "Iteration 66, loss = 103615.09308126\n",
      "Iteration 67, loss = 102031.15237039\n",
      "Iteration 68, loss = 102086.20952797\n",
      "Iteration 69, loss = 101587.01479699\n",
      "Iteration 70, loss = 100904.06930146\n",
      "Iteration 71, loss = 102021.41708470\n",
      "Iteration 72, loss = 101583.10277872\n",
      "Iteration 73, loss = 100675.53641603\n",
      "Iteration 74, loss = 100901.27979784\n",
      "Iteration 75, loss = 100644.43795074\n",
      "Iteration 76, loss = 100824.11527940\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "regr_log = MLPRegressor(activation=\"logistic\",random_state=1, max_iter=500, verbose=1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 581.39631976, 3873.25361904])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr_log.predict(X_test[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Layer\n",
    " * (100,) gives score 0.8985633080113131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8955647855414062"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr_log.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 3201837.93870370\n",
      "Iteration 2, loss = 1991411.34130691\n",
      "Iteration 3, loss = 1207776.57987225\n",
      "Iteration 4, loss = 829918.32614717\n",
      "Iteration 5, loss = 701563.17847012\n",
      "Iteration 6, loss = 609849.33922636\n",
      "Iteration 7, loss = 566002.48355765\n",
      "Iteration 8, loss = 541823.07092906\n",
      "Iteration 9, loss = 528819.74398157\n",
      "Iteration 10, loss = 496466.92430095\n",
      "Iteration 11, loss = 476056.58618350\n",
      "Iteration 12, loss = 497714.10481122\n",
      "Iteration 13, loss = 479039.95021325\n",
      "Iteration 14, loss = 455056.43346666\n",
      "Iteration 15, loss = 445080.70196828\n",
      "Iteration 16, loss = 409322.23690316\n",
      "Iteration 17, loss = 366980.02382337\n",
      "Iteration 18, loss = 346183.89037226\n",
      "Iteration 19, loss = 323250.12026869\n",
      "Iteration 20, loss = 326523.36060259\n",
      "Iteration 21, loss = 308932.72362820\n",
      "Iteration 22, loss = 279639.83960842\n",
      "Iteration 23, loss = 257296.53289489\n",
      "Iteration 24, loss = 247172.38096642\n",
      "Iteration 25, loss = 232067.37979024\n",
      "Iteration 26, loss = 223880.00751534\n",
      "Iteration 27, loss = 213786.60226812\n",
      "Iteration 28, loss = 208901.39270935\n",
      "Iteration 29, loss = 198351.62287402\n",
      "Iteration 30, loss = 204145.40098627\n",
      "Iteration 31, loss = 201315.62248731\n",
      "Iteration 32, loss = 216178.20061403\n",
      "Iteration 33, loss = 192496.70349919\n",
      "Iteration 34, loss = 182510.37738588\n",
      "Iteration 35, loss = 174524.86158493\n",
      "Iteration 36, loss = 171490.88069958\n",
      "Iteration 37, loss = 168322.41063616\n",
      "Iteration 38, loss = 166619.37550302\n",
      "Iteration 39, loss = 169041.78030520\n",
      "Iteration 40, loss = 165717.68262491\n",
      "Iteration 41, loss = 162699.51708955\n",
      "Iteration 42, loss = 161255.66101281\n",
      "Iteration 43, loss = 160427.14934315\n",
      "Iteration 44, loss = 158994.93191146\n",
      "Iteration 45, loss = 158668.89435536\n",
      "Iteration 46, loss = 160469.54534695\n",
      "Iteration 47, loss = 158897.00778347\n",
      "Iteration 48, loss = 155451.52672563\n",
      "Iteration 49, loss = 153732.26824145\n",
      "Iteration 50, loss = 152462.86026982\n",
      "Iteration 51, loss = 151733.19635404\n",
      "Iteration 52, loss = 151704.05850993\n",
      "Iteration 53, loss = 144416.83759078\n",
      "Iteration 54, loss = 142748.41372758\n",
      "Iteration 55, loss = 141763.32359329\n",
      "Iteration 56, loss = 144570.05362576\n",
      "Iteration 57, loss = 141154.27711828\n",
      "Iteration 58, loss = 159131.89725174\n",
      "Iteration 59, loss = 157629.87094076\n",
      "Iteration 60, loss = 155773.29178963\n",
      "Iteration 61, loss = 151913.64160054\n",
      "Iteration 62, loss = 151126.64789251\n",
      "Iteration 63, loss = 156981.95823415\n",
      "Iteration 64, loss = 153677.58146046\n",
      "Iteration 65, loss = 151565.35205966\n",
      "Iteration 66, loss = 150949.84547914\n",
      "Iteration 67, loss = 150393.37064816\n",
      "Iteration 68, loss = 148523.34336914\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "regr_tanh=MLPRegressor(activation=\"tanh\",random_state=1, max_iter=500, verbose=1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8448518799886"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr_tanh.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def net_train_and_predict(X_train, y_train, X_pred, alpha, random_state, verbose = False):\n",
    "    start_time = time.time()\n",
    "\n",
    "    scaler_x = MaxStdScaler()\n",
    "    X_train = scaler_x.fit_transform(X_train)\n",
    "    scaler_y = MaxStdScaler(factor = 15.0)\n",
    "    y_train = scaler_y.fit_transform(y_train)\n",
    "\n",
    "    regressor = MLPRegressor(hidden_layer_sizes = (100, 75, 50, 25), activation = 'relu', solver = 'sgd', learning_rate = 'adaptive', alpha = alpha, random_state = random_state)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    print(regressor.loss_)\n",
    "\n",
    "    y_pred = scaler_y.inverse_transform(regressor.predict(scaler_x.transform(X_pred)), copy = False)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Deep regressor traning and predicting finished. Time spent = {:.2f}s.\".format(end_time - start_time))\n",
    "\n",
    "    return y_pred "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
